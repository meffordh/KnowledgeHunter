Skip to content
Files
Commands
Search
Packager files
Config files
dynamic-deep-research-specification.md
Add a new feature. dynamic-deep-research-specification.md

Just now
ME

meffordh

AI
I notice that the specification file couldn't be loaded properly. Could you please describe the feature you'd like to add to the ResearchHunter platform? This will help me create a detailed plan that aligns with your requirements.

Just now
Paused (Agent is waiting for your response)

Message Agent…
Product Requirements Document: LinkedIn Social Sharing Module
Overview
This module enables authenticated users of ResearchHunter to share their deep research reports as LinkedIn articles directly from the application. By leveraging the captured w_member_social scope (along with r_liteprofile and email) via Clerk’s social connection, the module will post the report on the user’s personal LinkedIn profile. The feature will then capture the unique LinkedIn post URN and store it in the database, allowing the system to award sharing credits to users. This integration enhances user engagement, expands report reach, and incentivizes social sharing.

Core Features
Social Sharing Integration
Clerk Integration:
Utilize the existing Clerk configuration that captures the w_member_social scope. This scope permits posting on behalf of an authenticated user.
LinkedIn API Usage:
Retrieve the user's unique LinkedIn URN via the /v2/me endpoint.
Construct a post payload for the /ugcPosts endpoint that includes:
The author field in the format urn:li:person:{userID}.
Lifecycle state set to "PUBLISHED".
Visibility set to "PUBLIC".
A specificContent object of type com.linkedin.ugc.ShareContent containing the report text and the URL (as an article).
Database Tracking:
Update the research report record (or a dedicated social shares table) with the returned LinkedIn post URN.
Increment the user’s sharing credits.
User Feedback & Error Handling
Display confirmation messages or error alerts on the research report view after a share attempt.
Log API errors and handle token or API failures gracefully.
Technical Requirements
Frontend
Framework & Language: React with TypeScript.
Styling: Tailwind CSS and Shadcn UI components.
New UI Component:
Add a “Share on LinkedIn” button in the research report view (e.g., in home-page.tsx or a dedicated component like ReportActions.tsx).
On click, initiate an API call (using fetch or Axios) to the new backend endpoint.
Data Management:
Use React Query to handle asynchronous API calls.
Provide user feedback (loading states, success/error notifications).
Backend
Server Framework: Express.js with TypeScript.
New API Endpoint:
Create a POST endpoint at /api/social/linkedin/share secured with Clerk’s requireAuth() middleware.
The endpoint should accept the research report ID or content and a short description.
Retrieve the user’s LinkedIn access token (ensuring it includes the w_member_social scope).
Call a dedicated module function (e.g., postToLinkedIn) to:
Fetch the user’s LinkedIn URN from /v2/me.
Construct and send the payload to the LinkedIn /ugcPosts endpoint with appropriate headers:
Authorization: Bearer <access_token>
LinkedIn-Version: 202401 (or another current version)
X-Restli-Protocol-Version: 2.0.0
Content-Type: application/json
Return the created LinkedIn post URN in the response.
Database Updates:
Modify the schema (in shared/schema.ts) to add a field (e.g., linkedinPostId) to the researchReports table or create a new table for social share records.
Update storage functions in server/storage.ts to support saving the post URN and incrementing user credits.
Testing & Logging:
Implement unit tests for the new LinkedIn integration module and API endpoint.
Log errors and monitor API call outcomes for debugging.
References & Useful URLs
Share on LinkedIn (Microsoft Docs)
Test your LinkedIn Connection (Clerk Docs)
Sign In with LinkedIn v2 (Microsoft Docs)
Success Criteria
The “Share on LinkedIn” button is visible on the research report page and initiates the sharing process.
A successful LinkedIn post returns a post URN, which is stored in the database.
The user's sharing credits are incremented upon successful sharing.
All code follows a modular design: the LinkedIn integration is encapsulated in a small, single-responsibility module.
Proper error handling and unit tests are in place.
Future Enhancements
Extend support for rich media posts (images, videos) and additional content types.
Add support for posting to LinkedIn company pages (requires additional scopes such as w_organization_social).
Integrate detailed analytics to track post performance using LinkedIn’s analytics endpoints.
Enhance the UI with scheduling options and post previews.
Timeline & Milestones
Design & Planning: 1 day
Development: 2–3 days (client-side button, backend API and module, database updates)
Testing & Debugging: 1–2 days
Deployment & Verification: 1 day
No file found at "attached_assets/clerk-documentation-express.txt", it may have been deleted
Secrets are accessible to anyone who has access to this App. To restrict secret access, you must update App invite permissions. For more information, visit our documentation.
DATABASE_URL
••••••••
PGDATABASE
••••••••
PGHOST
••••••••
PGPORT
••••••••
PGUSER
••••••••
PGPASSWORD
••••••••
AUTH_LINKEDIN_CLIENT_ID
••••••••
AUTH_LINKEDIN_CLIENT_SECRET
••••••••
CLERK_PUBLISHABLE_KEY
••••••••
CLERK_SECRET_KEY
••••••••
VITE_CLERK_PUBLISHABLE_KEY
••••••••
CLERK_LINKEDIN_CLIENT_ID
••••••••
CLERK_LINKEDIN_CLIENT_SECRET
••••••••
CLERK_LINKEDIN_CLIENT_ID
••••••••
CLERK_LINKEDIN_CLIENT_SECRET
••••••••
FIRECRAWL_API_KEY
••••••••
LINKEDIN_CLIENT_ID
••••••••
LINKEDIN_CLIENT_SECRET
••••••••
OPENAI_API_KEY
••••••••
/

Deploying
Started 2 minutes ago by meffordh
Production
Status
meffordh deployed about 21 hours ago
Domain
https://deep-research-web-interface-meffordh.replit.app
Type
Autoscale
(4 vCPU / 8 GiB RAM / 3 Max)
See all usage
fad2fe64
ME

meffordh
meffordh
deployed 1 day ago
5556a7dc
ME

meffordh
meffordh
deployed 1 day ago
b88f9f07
ME

meffordh
meffordh
deployed 1 day ago
124a9af3
ME

meffordh
meffordh
deployed 1 day ago
ab6ed6b3
ME

meffordh
meffordh
deployed 1 day ago
14811eb2
ME

meffordh
meffordh
deployed 1 day ago
7018fc30
ME

meffordh
meffordh
deployed 1 day ago
a9ae5f6f
ME

meffordh
meffordh
deployed 3 days ago
9b6f5923
ME

meffordh
meffordh
deployed 3 days ago
e18e9ed8
ME

meffordh
meffordh
deployed 3 days ago
920edf0f
ME

meffordh
meffordh
deployed 3 days ago
c69e983b
ME

meffordh
meffordh
deployed 3 days ago
406c3a1c
ME

meffordh
meffordh
deployed 3 days ago
453f94de
ME

meffordh
meffordh
failed to deploy 3 days ago
ee3827cb
ME

meffordh
meffordh
failed to deploy 3 days ago
09b836ef
ME

meffordh
meffordh
deployed 3 days ago
36c486ae
ME

meffordh
meffordh
deployed 3 days ago
33896787
ME

meffordh
meffordh
deployed 3 days ago
7c658b8e
ME

meffordh
meffordh
deployed 3 days ago
26cd3350
ME

meffordh
meffordh
failed to deploy 3 days ago
7fd4c1dd
ME

meffordh
meffordh
deployed 3 days ago
14f2a32f
ME

meffordh
meffordh
deployed 3 days ago
9ec1cf42
ME

meffordh
meffordh
failed to deploy 3 days ago
366d539c
ME

meffordh
meffordh
deployed 3 days ago
4a0f7bca
ME

meffordh
meffordh
deployed 3 days ago
c0cb9d8f
ME

meffordh
meffordh
deployed 3 days ago
a1b9996e
ME

meffordh
meffordh
deployed 3 days ago
c6bb6e80
ME

meffordh
meffordh
deployed 3 days ago
1f810f06
ME

meffordh
meffordh
deployed 4 days ago
ca244035
ME

meffordh
meffordh
deployed 4 days ago
c1801068
ME

meffordh
meffordh
deployed 4 days ago
275fdba3
ME

meffordh
meffordh
deployed 4 days ago
90724839
ME

meffordh
meffordh
deployed 4 days ago
0feb90ea
ME

meffordh
meffordh
deployed 4 days ago
9b39b231
ME

meffordh
meffordh
deployed 4 days ago
c3342f13
ME

meffordh
meffordh
deployed 4 days ago
3e2f21d6
ME

meffordh
meffordh
deployed 4 days ago
275a8ece
ME

meffordh
meffordh
deployed 4 days ago
a6933f44
ME

meffordh
meffordh
deployed 4 days ago
61f40ba7
ME

meffordh
meffordh
deployed 4 days ago
be3af228
ME

meffordh
meffordh
deployed 4 days ago
Login with Replit
Run your web app to use Log in with Replit
Remote Updates
origin/main•upstream
last fetched 1 day ago
12 commits to push
Commit
Summary of your commit...
2 changed files
dynamic-deep-research-specification_md.md
Added
dynamic-deep-research-specification.md
Added
Committing will automatically stage your changes.


Unified

Split
# ResearchHunter

ResearchHunter is an intelligent web-based research platform designed to simplify complex information gathering through advanced AI-powered authentication and data retrieval mechanisms. The application focuses on robust, scalable OAuth integration with comprehensive error handling and social platform connectivity.

## Features

- AI-powered research assistance using OpenAI GPT-4
- LinkedIn OAuth authentication with OpenID Connect
- Real-time research progress tracking via WebSocket
- Persistent storage with PostgreSQL
- Comprehensive error handling and logging
- TypeScript/Node.js backend with Express
- React frontend with shadcn/ui components
- WebSocket for real-time communication
- Firecrawl integration for web crawling

## Prerequisites

- Node.js 20.x or higher
- PostgreSQL database
- LinkedIn Developer account
- OpenAI API key
- Firecrawl API key

⦚ 56 unchanged lines ⦚
│   ├── deep-research.ts # Research logic
│   ├── routes.ts        # API routes
│   └── storage.ts       # Database interface
└── shared/              # Shared types and schemas
```

## API Documentation

### Authentication Endpoints

- `POST /api/register` - Register a new user
- `POST /api/login` - Login with email/password
- `GET /api/auth/linkedin` - Initiate LinkedIn OAuth flow
- `GET /api/auth/linkedin/callback` - LinkedIn OAuth callback
- `POST /api/logout` - Logout current user
- `GET /api/user` - Get current user information

### Research Endpoints

- `POST /api/clarify` - Generate clarifying questions
- `GET /api/research/history` - Get user's research history
- `WebSocket /ws` - Real-time research updates

## Development Guidelines

- Follow the TypeScript coding style
- Use Drizzle ORM for database operations
- Implement proper error handling
- Add comprehensive logging
- Test authentication flows thoroughly

## License

MIT

## Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

graph TD
    A[User Input] --> B[Clarifying Questions]
    B --> C[Research Parameters]
    C --> D[Initial Query Processing]
    D --> E{Depth Level Loop}
    E --> F[Query Expansion]
    F --> G[Web Crawling]
    G --> H[Content Analysis]
    H --> I[Knowledge Extraction]
    I --> J{More Depth?}
    J -->|Yes| E
    J -->|No| K[Report Generation]
    K --> L[Source Citation]
    L --> M[Final Report]
```

## Prerequisites

- Node.js 20.x or higher
- PostgreSQL database
- Clerk account
- OpenAI API key
- Firecrawl API key

⦚ 56 unchanged lines ⦚
│   ├── deep-research.ts # Research logic
│   ├── routes.ts        # API routes
│   └── storage.ts       # Database interface
└── shared/              # Shared types and schemas
The agent needs your feedback.
6m
 • 
7 minutes ago
Port :5000 opened on
Your task is to implement a feature update/bug fix for the LinkedIn share functionality in the ResearchHunter repository. The current issues are that the share button does not yield a valid token from Clerk for LinkedIn integration, and the token and scope checking logic is inconsistent between the client and backend. Follow these steps:

Client-Side (in client/src/components/ui/share-button.tsx):

Update the token retrieval so that the call to window.Clerk.getToken() is modified (if needed) to request an access token that includes the w_member_social scope. (If an options object is supported by Clerk to request additional scopes, include it.)
Improve the logic that checks for the required scope. For example, if approved_scopes is returned as a comma-separated string rather than an array, split it into an array before checking for 'w_member_social'.
Add enhanced error logging and display a clear toast message that instructs users to reconnect their LinkedIn account via account settings if the token is missing or the required scope is absent.
Capture a screenshot of the modified share button code and any updated UI toast message on error.
Backend (in server/linkedin.ts):

Update the token handling so that instead of solely relying on the token stored in req.auth.sessionClaims (or extracted from external accounts), the backend will also accept and use the token sent from the client (if valid). This unifies the token source between client and server.
Enhance scope verification: Ensure that the backend checks whether the approved_scopes (which might be a string) includes 'w_member_social'. Log detailed messages indicating whether the token is present and has the proper scopes.
Maintain existing logging that outputs whether a LinkedIn account is connected, if the token exists, and whether it has the required permissions.
Capture a screenshot of the updated backend code (e.g. the token extraction and scope checking in server/linkedin.ts) with the added logs.
Documentation (in docs/linkedin-share.md):

Update the document to include troubleshooting steps for token and scope issues.
Reference the following URLs for further guidance:
Clerk LinkedIn Connection Guide: https://clerk.com/docs/authentication/social-connections/linkedin-oidc#test-your-connection
LinkedIn Share Documentation: https://learn.microsoft.com/en-us/linkedin/consumer/integrations/self-serve/share-on-linkedin
Capture a screenshot of the updated documentation file.
General Instructions:

Ensure that when a user clicks the “Share on LinkedIn” button, the flow retrieves a token that includes the w_member_social permission. If the token is invalid or missing the required scope, display a toast message advising the user to reconnect their LinkedIn account.
Make sure that debug logging in both the client and server clearly states whether the token is valid, whether the required scope is present, and any errors encountered.
Update Specification: Automatic Research Parameter Customization with Dynamic Model Selection and Verbose Report Generation Overview Currently, the deep research workflow requires users to manually supply numeric parameters (“breadth” and “depth”) along with their research query. These fields have proven confusing. In this update, you will remove these manual inputs from the UI and instead have the system automatically determine optimal research parameters before starting research. In addition, you will now:

Generate a final research report that is more verbose and detailed.

Improve the trimming functionality so that input text is only shortened if it exceeds the token limit for the chosen model.

Dynamically select the appropriate model based on performance requirements:

Use a fast model (gpt-4o‑mini) when speed is paramount. Use the balanced model (gpt-4o) when both speed and depth are important. Use a deep reasoning model (o3‑mini) when the query requires extensive reasoning. Update the prompting for report generation so that the report structure is dynamically determined based on the query and findings. (For example, if the query implies a ranked “top‑N” list, the prompt instructs the model to output numbered sections and detailed explanations.)

Objectives & User Outcomes Simplify Research Initiation: Users now only need to enter their research query (and later answer any clarifying questions) without worrying about numeric parameters.

Automated Parameter Selection: The system will analyze the query via an AI call and determine appropriate “breadth” and “depth” values before research begins. If the determination fails, default values (e.g. breadth: 4, depth: 2) will be used.

Dynamic and Verbose Report Output: The final research report will be generated with greater verbosity and a dynamic, context‐sensitive structure (using markdown) that fits the query. For example, if the query suggests ranking, the report will include a clearly numbered ranked list with supporting details.

Optimized Model Selection and Trimming:

The system will choose between different AI models: gpt-4o-mini when speed is the highest priority. gpt-4o for balanced speed and depth. o3-mini when deep reasoning is required. The “trimPrompt” function will be updated so that it only trims the text if the encoded tokens exceed the token limit for the chosen model (e.g. allowing longer inputs for models with very large context windows). Error Handling and Logging: Clear logging (using the existing log function) will indicate which parameters were auto-determined, and any errors in the parameter determination or API calls will be logged and gracefully handled with fallback defaults.

Technical Requirements Frontend Remove Manual Parameter Inputs

File: client/src/pages/home-page.tsx Task:

Remove the two blocks that render numeric  fields for “breadth” and “depth.” Update the form’s default values and the research schema so that only the “query” (and, if applicable, clarifying question answers) are collected. In the submission handler (onSubmit), remove any code that reads “breadth” and “depth” values. Instead, send only the query (and clarifications) to the backend. Outcome: The research form now only prompts for a research query and (if needed) answers to clarifying questions.

User Feedback for Auto-Determination

File: client/src/pages/home-page.tsx Task: Optionally add a UI indicator (for example, a spinner or note “determining optimal parameters…”) when the research process begins. Outcome: Users see a brief loading indicator as the system auto-determines research parameters. Shared Schema Update Modify Research Schema

File: shared/schema.ts Task: In the researchSchema definition, remove (or mark as optional) the breadth and depth fields so that the client submission does not include them (they can still be stored for logging/debug purposes if desired). Outcome: The research submission from the client only includes the query and (optionally) clarifications. Backend Implement Auto-Determination of Research Parameters

File: server/deep-research.ts Task: New Helper Function: Implement an async helper function determineResearchParameters(query: string): Promise<{ breadth: number; depth: number }> that uses the OpenAI API to analyze the complexity of the query and return recommended numeric values. For example, use a dedicated prompt such as:

“Given this research query: [query], determine optimal research settings. Provide a JSON response with keys ‘breadth’ (a number between 2 and 10) and ‘depth’ (a number between 1 and 5).”

Error Handling: If the API call fails or returns unexpected values, log the error (using the log function) and fall back to default values (breadth: 4, depth: 2).

Dynamic Model & Trimming Updates:

Model Selection: Introduce a parameter (e.g. mode or priority) in the research request that determines which model to use:

For speed-critical cases, select "gpt-4o-mini-2024-07-18". For balanced performance, select "gpt-4o-2024-08-06" (or a similar snapshot). For deep reasoning, select "o3-mini-2025-01-31". (If no explicit mode is provided, the system may default to the balanced model.)

Trimming Function Update: Update the trimPrompt function so that it accepts the target model as a parameter and uses the appropriate token limit. For instance, allow longer inputs for models with a 128,000-token context window and only trim if the encoded text exceeds that limit. For smaller models (e.g. gpt-4o-mini), use a stricter limit.

Dynamic Report Generation Prompt: In the formatReport function:

Update the prompt to instruct the model to generate a verbose, detailed report. First, determine an optimal report structure (e.g. by calling a helper like determineReportStructure(query, learnings)) that returns section headings (such as “Introduction”, “Ranked Findings”, “Conclusion”, “Sources”). Instruct the model to follow that structure. If the research query suggests a ranking (by detecting keywords like “top”, “best”, “ranking”), require the model to output a clearly numbered list with supporting details. Emphasize the use of markdown formatting. Outcome: The helper function returns an object with numeric breadth and depth values that are merged into the research object before the research loop begins. All subsequent API calls (clarifying questions, query expansion, report generation) will use the selected model and updated trimming logic. Integrate Auto-Determination into the Research Flow

Files: server/routes.ts and server/deep-research.ts Task: In the WebSocket message handler (in server/routes.ts) and/or at the start of the handleResearch() function in server/deep-research.ts, call the new determineResearchParameters(query) function. Merge the auto-determined parameters into the research object before continuing with the research loop. Remove any reliance on client-supplied “breadth” and “depth” values. Outcome: The research process uses system-determined parameters based solely on the query and optionally an externally specified mode. Documentation & Logging

Task: Add logging statements (using the existing log function in server/vite.ts) to print out the auto-determined parameters and the selected model for debugging purposes. Update error handling so that if auto-determination fails, the error is logged and default values are used. Outcome: Easier troubleshooting and clarity on which parameters and models are used for each research session. Testing & Validation Unit & Integration Tests

Task: Write unit tests for the new function determineResearchParameters(query) (for example, under server/tests/). Manually test the research flow by: Entering a query on the home page. Verifying that no “breadth” or “depth” fields are visible. Confirming via logs or debug output that optimal parameters (and the selected model and token limits) have been determined. Checking that the final research report is verbose and structured according to the dynamic prompt, and that the trimming function respects model-specific token limits. Outcome: The research process auto-determines its parameters, chooses the appropriate AI model, and produces a detailed research report while the UI remains simplified. User Feedback

Task: Confirm that any toasts or notifications do not refer to missing manual parameter input. Verify that error messages refer only to issues like connection errors or failure in auto-configuration, not missing numeric fields. Outcome: A smoother user experience with a clear indication that the research parameters are determined automatically, and a final report generated using AI-driven parameters that match the desired performance (speed, balanced, or deep reasoning). Summary of Steps Frontend Remove Manual Inputs: Delete the “breadth” and “depth” inputs from client/src/pages/home-page.tsx. Update Form Defaults: Adjust the form’s default values and submission handler to only collect “query” (and clarifications if needed). User Feedback: Optionally add a UI indicator (spinner or note) showing that optimal parameters are being determined. Shared Schema Modify researchSchema: Remove or mark the breadth and depth fields as optional in shared/schema.ts so they are not provided by the client. Backend Implement determineResearchParameters(): In server/deep-research.ts, create a helper function that uses the OpenAI API (with a dedicated prompt such as “Given this research query…”) to return an object with breadth and depth. Fall back to default values (4 and 2) on error. Update Trimming Function: Modify the trimPrompt function to accept a model parameter and use token limits based on the chosen model. Dynamic Model Selection: Based on a “mode” (or similar parameter), select the AI model: Use gpt-4o-mini for speed. Use gpt-4o for balanced performance. Use o3-mini for deep reasoning. Dynamic Prompting for Report Structure: Update the prompt in the report-generation function (formatReport) so that the model: First, is asked to determine an optimal structure for the report. Then, uses that structure to generate a verbose, markdown-formatted report. Adjusts the prompt if the query implies a ranked list. Integrate Auto-Determination: In server/routes.ts and within handleResearch(), call determineResearchParameters(query), merge the returned values into the research object, and remove any reliance on client-supplied numeric values. Logging and Error Handling: Add logging statements for debugging (including the selected model and parameters). Fall back to default values on any API errors. Testing & Validation Unit Test: Write tests for determineResearchParameters(). Manual Testing: Verify that: No manual “breadth” or “depth” fields appear. Backend logs show auto-determined parameters and selected model. The final report is verbose, structured, and respects model-specific token limits. User Toasts: Ensure that notifications are clear and do not reference missing manual input.

